{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create the datasets using significant features\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "## high utilization and non-fraudulent\n",
    "significant = defaultdict(int)\n",
    "for dataset in data_merged:\n",
    "    pvalues = {}\n",
    "    for f in dataset.columns:\n",
    "        group1 = dataset.loc[flag == 'high utilization', f]\n",
    "        group2 = dataset.loc[flag == 'non-fraudulent', f]\n",
    "        val = ttest_ind(group1.values, group2.values)[1]\n",
    "        if str(val) != 'nan' :\n",
    "            pvalues[f] = val\n",
    "            \n",
    "    p = 0.1/len(dataset.columns)\n",
    "\n",
    "    for f in pvalues:\n",
    "        if pvalues[f] < p:\n",
    "            significant[f] += 1\n",
    "            \n",
    "significant_codes_HN = list(set([i[:5] for i in significant.keys()]))\n",
    "\n",
    "## fraudulent and non-fraudulent\n",
    "significant = defaultdict(int)\n",
    "for dataset in data_merged:\n",
    "    pvalues = {}\n",
    "    for f in dataset.columns:\n",
    "        group1 = dataset.loc[flag == 'fraudulent', f]\n",
    "        group2 = dataset.loc[flag == 'non-fraudulent', f]\n",
    "        val = ttest_ind(group1.values, group2.values)[1]\n",
    "        if str(val) != 'nan' :\n",
    "            pvalues[f] = val\n",
    "            \n",
    "    p = 0.1/len(dataset.columns)\n",
    "\n",
    "    for f in pvalues:\n",
    "        if pvalues[f] < p:\n",
    "            significant[f] += 1\n",
    "            \n",
    "significant_codes_FN = list(set([i[:5] for i in significant.keys()]))\n",
    "\n",
    "## fraudulent and high utilization\n",
    "significant = defaultdict(int)\n",
    "for dataset in data_merged:\n",
    "    pvalues = {}\n",
    "    for f in dataset.columns:\n",
    "        group1 = dataset.loc[flag == 'fraudulent', f]\n",
    "        group2 = dataset.loc[flag == 'high utilization', f]\n",
    "        val = ttest_ind(group1.values, group2.values)[1]\n",
    "        if str(val) != 'nan' :\n",
    "            pvalues[f] = val\n",
    "            \n",
    "    p = 0.1/len(dataset.columns)\n",
    "\n",
    "    for f in pvalues:\n",
    "        if pvalues[f] < p:\n",
    "            significant[f] += 1\n",
    "            \n",
    "significant_codes_FH = list(set([i[:5] for i in significant.keys()]))\n",
    "\n",
    "## Feature selection\n",
    "codes_to_use = list(set([*significant_codes_HN, *significant_codes_FN, *significant_codes_FH]))\n",
    "\n",
    "data_merged_afs = []\n",
    "for i in range(len(data_merged)):\n",
    "    clmns = list(data_merged[i].columns)\n",
    "    clmns_to_use = [hcpcs for hcpcs in clmns if hcpcs[0:5] in codes_to_use]\n",
    "    data_merged_afs.append(data_merged[i][clmns_to_use])\n",
    "        \n",
    "# [x_MP, x_NoS, x_Ratio] = data_merged_afs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the datasets using only overused CPT codes\n",
    "\n",
    "overused_codes_before = ['14061', '65800', '65855', '67973', '67975', '68326', '68335', \n",
    "                         '76510', '76511', '76512', '76513', '92060', '92100', '92235', \n",
    "                         '92240', '92275', '92284', '95004', '95930']\n",
    "\n",
    "overused_codes_march8 = ['65100', '65210', '65222', '65400', '65426', '65722', '65815', \n",
    "                        '66030', '66175', '66183', '66761', '66982', '67938', '68761', \n",
    "                        '68801', '76514', '92020', '92025', '92065', '92083', '92140', \n",
    "                        '92225', '92226', '92250', '92286', '99354']\n",
    "\n",
    "## Get rid of the 1-3 codes\n",
    "# em_codes = ['99201', '99202', '99203', '99204', '99205',\n",
    "#             '99211', '99212', '99213', '99214', '99215',\n",
    "#             '99221', '99222', '99223',\n",
    "#             '99231', '99232', '99233',\n",
    "#             '99241', '99242', '99243', '99244', '99245',\n",
    "#             '99251', '99252', '99253', '99254', '99255',\n",
    "#             '99281', '99282', '99283', '99284', '99285',\n",
    "#             '99304', '99305', '99306', '99307', '99308', '99309', '99310']\n",
    "\n",
    "em_codes = ['99204', '99205',\n",
    "            '99214', '99215',\n",
    "            '99284', '99285',\n",
    "            '99304', '99305', '99306', '99307', '99308', '99309', '99310']\n",
    "\n",
    "# ## Get rid of 92002 and 92012\n",
    "# eye_visit_codes = ['92002', '92004', \n",
    "#                    '92012', '92014']\n",
    "\n",
    "eye_visit_codes = ['92004', \n",
    "                   '92014']\n",
    "\n",
    "## Feature selection\n",
    "codes_to_use = [*overused_codes_before, *overused_codes_march8, *em_codes, *eye_visit_codes]\n",
    "\n",
    "data_merged_afs = []\n",
    "for i in range(len(data_merged)):\n",
    "    clmns = list(data_merged[i].columns)\n",
    "    clmns_to_use = [hcpcs for hcpcs in clmns if hcpcs[0:5] in codes_to_use]\n",
    "    data_merged_afs.append(data_merged[i][clmns_to_use])\n",
    "        \n",
    "[x_MP, x_NoS, x_Ratio] = data_merged_afs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following codes could not be found in our merged dataset:**\n",
    "\n",
    "65100, 65722, 67973\n",
    "\n",
    "Consultation Codes: 99241, 99242, 99243, 99244, 99245, 99251, 99252, 99253, 99254, 99255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_MP_train, x_MP_unlabeled = x_MP.loc[flag != 'unlabeled'], x_MP.loc[flag == 'unlabeled']\n",
    "x_NoS_train, x_NoS_unlabeled = x_NoS.loc[flag != 'unlabeled'], x_NoS.loc[flag == 'unlabeled']\n",
    "x_Ratio_train, x_Ratio_unlabeled = x_Ratio.loc[flag != 'unlabeled'], x_Ratio.loc[flag == 'unlabeled']\n",
    "\n",
    "y_train = flag[flag != 'unlabeled']\n",
    "\n",
    "## Choosing a dedicated validation set\n",
    "idx_fraud = y_train[y_train == 'fraudulent'].index\n",
    "idx_high_utilization = y_train[y_train == 'high utilization'].index\n",
    "idx_non_fraud = y_train[y_train == 'non-fraudulent'].index\n",
    "\n",
    "\n",
    "idx_fraud_val = np.sort(np.random.choice(idx_fraud, size=len(idx_fraud) // 4, replace=False))\n",
    "idx_high_utilization_val = np.sort(np.random.choice(idx_high_utilization, size=len(idx_high_utilization) // 4, replace=False))\n",
    "idx_non_fraud_val = np.sort(np.random.choice(idx_non_fraud, size=len(idx_non_fraud) // 4, replace=False))\n",
    "idx_val = np.sort(np.concatenate((idx_fraud_val, idx_high_utilization_val, idx_non_fraud_val)))\n",
    "\n",
    "x_MP_val = x_MP_train.loc[idx_val]\n",
    "x_NoS_val = x_NoS_train.loc[idx_val]\n",
    "x_Ratio_val = x_Ratio_train.loc[idx_val]\n",
    "y_val = y_train[idx_val]\n",
    "len_val = len(y_val)\n",
    "\n",
    "x_MP_train = x_MP_train.drop(index=idx_val)\n",
    "x_NoS_train = x_NoS_train.drop(index=idx_val)\n",
    "x_Ratio_train = x_Ratio_train.drop(index=idx_val)\n",
    "y_train = y_train.drop(index=idx_val)\n",
    "len_train = len(y_train)\n",
    "\n",
    "x_stacked = [np.vstack((x_MP_train, x_MP_val)), np.vstack((x_NoS_train, x_NoS_val)), np.vstack((x_Ratio_train, x_Ratio_val))]\n",
    "y_stacked = np.concatenate((y_train, y_val))\n",
    "\n",
    "x_concat = np.concatenate((x_stacked[0], x_stacked[1], x_stacked[2]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using spy() method to see how sparse our input matrices are\n",
    "# plt.figure(figsize=(10, 40))\n",
    "# plt.spy(x_concat)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 20))\n",
    "titles = ['MP', 'NoS', 'Ratio']\n",
    "for i in range(len(x_stacked)):\n",
    "    axs[i].spy(x_stacked[i])\n",
    "    axs[i].set_title(titles[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert dataset type from dense to sparse\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# x_concat_sparse = csr_matrix(x_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Logistic Regression, SVM, and K-Nearest Neighbor classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the required modules\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, validation_curve, GridSearchCV, PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, RFE, chi2, VarianceThreshold, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using a balanced dataset\n",
    "\n",
    "# idx_fraud = y_train[y_train == 'fraudulent'].index\n",
    "# idx_non_fraud = y_train[y_train == 'non-fraudulent'].index\n",
    "\n",
    "# min_len = min(len(idx_fraud), len(idx_non_fraud))\n",
    "# idx_fraud_b = np.sort(np.random.choice(idx_fraud, size=min_len, replace=False))\n",
    "# idx_non_fraud_b = np.sort(np.random.choice(idx_non_fraud, size=min_len, replace=False))\n",
    "# idx_to_keep = np.sort(np.concatenate((idx_fraud_b, idx_non_fraud_b)))\n",
    "\n",
    "# x_MP_train_b = x_MP_train.loc[idx_to_keep]\n",
    "# x_NoS_train_b = x_NoS_train.loc[idx_to_keep]\n",
    "# x_Ratio_train_b = x_Ratio_train.loc[idx_to_keep]\n",
    "# y_train_b = y_train[idx_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data standardization\n",
    "x_SCALE = []\n",
    "for x in x_stacked:\n",
    "    x_SCALE.append(StandardScaler().fit_transform(x))\n",
    "    \n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 20))\n",
    "label = ['MP', 'NoS', 'Ratio']\n",
    "for i in range(len(x_SCALE)):\n",
    "    axs[i].spy(x_SCALE[i])\n",
    "    axs[i].set_title('{}'.format(label[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Feature selection using statistical methods (Filter methods)\n",
    "# x_STAT = [SelectKBest(chi2, k=50).fit_transform(x_concat, y_stacked)]\n",
    "x_STAT = []\n",
    "for x in x_stacked:\n",
    "    x_STAT.append(VarianceThreshold().fit_transform(x, y_stacked))\n",
    "\n",
    "# x_STAT_2 = []\n",
    "# for x in x_STAT:\n",
    "#     x_STAT_2.append(SelectKBest(f_classif, k=50).fit_transform(x, y_stacked))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 20))\n",
    "label = ['MP', 'NoS', 'Ratio']\n",
    "for i in range(len(x_STAT)):\n",
    "    axs[i].spy(x_STAT[i])\n",
    "    axs[i].set_title('{}'.format(label[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Dimensionality reduction using PCA \n",
    "labels = ['MP', 'NoS', 'Ratio']\n",
    "for i in range(3):\n",
    "    pca = PCA().fit(x_STAT[i])\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), label=labels[i])\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.legend()\n",
    "\n",
    "n = 50 # number of components to keep\n",
    "x_PCA = []\n",
    "for x in x_STAT:\n",
    "    pca = PCA(n_components=n)\n",
    "    z = StandardScaler().fit_transform(x)\n",
    "    pca.fit(z)\n",
    "    x_PCA.append(pca.transform(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensionality reduction using NMF\n",
    "model = NMF(n_components=100, init='random', random_state=0, max_iter=10000)\n",
    "x_NMF = []\n",
    "for x in x_STAT:\n",
    "    x_NMF.append(model.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature selection using RFE (Wrapper methods)\n",
    "estimator = DecisionTreeClassifier(max_depth=100, max_leaf_nodes=100, min_samples_leaf=6, random_state=0)\n",
    "# estimator =  LinearSVC(C=1, max_iter=1e6, penalty='l1', dual=False)\n",
    "selector = RFE(estimator, n_features_to_select=50, step=1)\n",
    "\n",
    "# z = StandardScaler().fit_transform(x_concat)\n",
    "# selector.fit(z, y_stacked)\n",
    "# x_RFE = [selector.fit_transform(z, y_stacked)]\n",
    "\n",
    "x_RFE = []\n",
    "for x in x_STAT:\n",
    "    z = StandardScaler(with_mean=False).fit_transform(x)\n",
    "    selector = selector.fit(z, y_stacked)\n",
    "    x_RFE.append(selector.fit_transform(z, y_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and choosing the best model using the dedicated validation set or cross validation\n",
    "# split = PredefinedSplit(test_fold=np.repeat([-1, 0], [len_train, len_val]))\n",
    "split = StratifiedKFold(4, shuffle=True, random_state=0)\n",
    "\n",
    "x_train = x_RFE\n",
    "\n",
    "parameters = {'svc__C':np.logspace(-4,4,10)}\n",
    "# parameters = {'lgr__C':np.logspace(-3,3,10)}\n",
    "# parameters = {'dt__max_depth':range(1,5), 'dt__min_samples_leaf':range(1,8),'dt__min_samples_split':[2, 3, 4],'dt__max_leaf_nodes':range(2,8)}\n",
    "# parameters = {'rf__max_depth':range(3,6),'rf__min_samples_leaf':range(2,6),'rf__min_samples_split':[2, 3, 4]}\n",
    "# parameters = {'ab__n_estimators':range(1,20),'ab__learning_rate':np.linspace(0.01,1,10)}\n",
    "# parameters = {'qda__reg_param':np.logspace(-4,-1,10)}\n",
    "\n",
    "scores = []\n",
    "hypers = []\n",
    "\n",
    "for x in x_train:\n",
    "#     pipelines might need ('scaler', StandardScaler())\n",
    "    clf_pipe = Pipeline([('svc', SVC(max_iter=1e9, kernel='rbf', gamma='auto'))])#\n",
    "#     clf_pipe = Pipeline([('scaler', StandardScaler()), ('svc', LinearSVC(max_iter=1e6, penalty='l2', dual=False))])\n",
    "#     clf_pipe = Pipeline([('scaler', StandardScaler()), ('lgr', LogisticRegression(max_iter=1e6, solver='lbfgs', penalty='l2'))])\n",
    "#     clf_pipe = Pipeline([('dt',DecisionTreeClassifier(random_state=0))])\n",
    "#     clf_pipe = Pipeline([('rf',RandomForestClassifier(random_state=0))])\n",
    "#     clf_pipe = Pipeline([('ab',AdaBoostClassifier(random_state=0))])\n",
    "#     clf_pipe = Pipeline([('qda', QuadraticDiscriminantAnalysis())])\n",
    "    clf_grid = GridSearchCV(clf_pipe, parameters, cv=split)\n",
    "    clf_grid.fit(x, y_stacked) \n",
    "    clf_best = clf_grid.best_estimator_\n",
    "    scores.append(np.mean(cross_val_score(clf_best, x, y_stacked, cv=split)))\n",
    "    hypers.append(clf_best.named_steps['svc'])\n",
    "    \n",
    "print('Best scores:', scores)\n",
    "print('Best hyperparameters:', hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-stage SVM\n",
    "\n",
    "    \n",
    "x_train = [x_stacked_SVM]\n",
    "\n",
    "ps = PredefinedSplit(test_fold=np.repeat([-1, 0], [len_train, len_val]))\n",
    "       \n",
    "parameters = {'svc__C':np.logspace(-4,4,10)}    \n",
    "\n",
    "scores = []\n",
    "hypers = []\n",
    "\n",
    "for x in x_train:\n",
    "    # ('scaler', StandardScaler()), \n",
    "    clf_pipe = Pipeline([('svc', LinearSVC(max_iter=1e6, penalty='l2', dual=False))])\n",
    "    clf_grid = GridSearchCV(clf_pipe, parameters, cv=ps)\n",
    "    clf_grid.fit(x, y_stacked)\n",
    "    clf_best = clf_grid.best_estimator_\n",
    "    scores.append(np.mean(cross_val_score(clf_best, x, y_stacked, cv=ps)))\n",
    "    hypers.append(clf_best.named_steps['svc'])\n",
    "    \n",
    "print('Scores on different feature sets:', scores)\n",
    "print('Best hyperparameters:', hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_NoS_train\n",
    "x_unlabeled = x_NoS_unlabeled\n",
    "# x_train = pd.concat([x_MP_train, x_NoS_train, x_Ratio_train], axis=1)\n",
    "\n",
    "clf = Pipeline([('svc', SVC(max_iter=1e6, C=46.416, kernel='rbf', gamma='scale'))])\n",
    "\n",
    "new_labels = clf.fit(x_train, y_train_b).predict(x_unlabeled)\n",
    "\n",
    "new_non_fraud_npi = x_unlabeled[new_labels == 'non-fraudulent'].index\n",
    "\n",
    "len(new_non_fraud_npi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting names corresponding to the fraudulent npis\n",
    "\n",
    "data2018 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2018_CA_Ophthalmology.csv')\n",
    "data2017 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2017_CA_Ophthalmology.csv')\n",
    "data2016 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2016_CA_Ophthalmology.csv')\n",
    "data2015 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2015_CA_Ophthalmology.csv')\n",
    "data2014 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2014_CA_Ophthalmology.csv')\n",
    "data2013 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_CY2013_CA_Ophthalmology.csv')\n",
    "data2013 = data2013.rename(columns={'National Provider Identifier ':'National Provider Identifier'})\n",
    "data2012 = pd.read_csv('D:\\\\Anaconda\\\\Jupyter Directory\\\\Medicare Fraud Detection\\\\MedicareData_California_Opthalmology\\\\Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_CY2012_CA_Ophthalmology.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=new_non_fraud_npi, columns=['Last Name', 'First Name'], dtype='str')\n",
    "\n",
    "for npi in new_non_fraud_npi:\n",
    "    d = data2012.loc[data2012['National Provider Identifier'] == npi]\n",
    "    if d.shape[0] != 0:\n",
    "        df.loc[npi] = d.iloc[0][['Last Name/Organization Name', 'First Name']].values\n",
    "\n",
    "df.to_csv(r'D:\\Anaconda\\Jupyter Directory\\Medicare Fraud Detection\\MedicareData_California_Opthalmology\\LoN_Mar22_potentially_nonfraud.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labeling the unlabeled data with -1\n",
    "\n",
    "y_num = y_stacked.copy()\n",
    "y_num[y_num == 'non-fraudulent'] = 0\n",
    "y_num[y_num == 'high utilization'] = 1\n",
    "y_num[y_num == 'fraudulent'] = 2\n",
    "\n",
    "# flag = pd.Series(data=[-1] * len(data_merged[0].index), index=data_merged[0].index, dtype='int', name='flag')\n",
    "# for npi in non_fraud:\n",
    "#      flag.at[npi] = 0\n",
    "# for npi in high_utilization:\n",
    "#     flag.at[npi] = 1\n",
    "# for npi in fraud:\n",
    "#     flag.at[npi] = 2\n",
    "    \n",
    "# x_MP_v, x_NoS_v, x_Ratio_v = x_MP.values, x_NoS.values, x_Ratio.values\n",
    "# y_v = flag.values\n",
    "\n",
    "y_lp = y_num.copy()\n",
    "y_lp[len_train:] = -1\n",
    "y_lp = y_lp.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_MP_c = [x_MP_fraud, x_MP_high_utilization, x_MP_non_fraud, x_MP_unlabeled] = \\\n",
    "# x_MP.loc[flag == 'fraudulent'], x_MP.loc[flag == 'high utilization'], x_MP.loc[flag == 'non-fraudulent'], x_MP.loc[flag == -1]\n",
    "\n",
    "# x_NoS_c = [x_NoS_fraud, x_NoS_high_utilization, x_NoS_non_fraud, x_NoS_unlabeled] = \\\n",
    "# x_NoS.loc[flag == 'fraudulent'], x_NoS.loc[flag == 'high utilization'], x_NoS.loc[flag == 'non-fraudulent'], x_NoS.loc[flag == -1]\n",
    "\n",
    "# x_Ratio_c = [x_Ratio_fraud, x_Ratio_high_utilization, x_Ratio_non_fraud, x_Ratio_unlabeled] = \\\n",
    "# x_Ratio.loc[flag == 'fraudulent'], x_Ratio.loc[flag == 'high utilization'], x_Ratio.loc[flag == 'non-fraudulent'], x_Ratio.loc[flag == -1]\n",
    "\n",
    "# y_train = flag[flag != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "x_train = x_stacked\n",
    "y = y_num[:len_train].astype('float64')\n",
    "\n",
    "predictions = []\n",
    "for x in x_train:\n",
    "    x_labeled, x_unlabeled = x[:len_train], x[len_train:]\n",
    "    knn.fit(x_labeled, y)\n",
    "    predictions.append(knn.predict(x_unlabeled))\n",
    "    \n",
    "# DF = pd.DataFrame(data=np.array(predictions).T, index=flag[flag==-1].index, columns=['MP', 'NoS', 'Ratio'], dtype='int')\n",
    "# DF.loc[knn_picked].iloc[10:20]\n",
    "# s = pd.Series(data=np.sum(np.array(predictions).T, axis=1), index=flag[flag==-1].index, dtype='int')\n",
    "# knn_picked = s[s>2].index\n",
    "# DF.loc[knn_picked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "sum(predictions[n] == y_num[len_train:]) / len(predictions[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Implementing the label propagation\n",
    "import sklearn\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "x = x_stacked[1]\n",
    "\n",
    "# def rbf_kernel_safe(X, Y=None, gamma=None): \n",
    "#     X, Y = sklearn.metrics.pairwise.check_pairwise_arrays(X, Y) \n",
    "#     if gamma is None: \n",
    "#         gamma = 1.0 / X.shape[1] \n",
    "#     K = sklearn.metrics.pairwise.euclidean_distances(X, Y, squared=True) \n",
    "#     K *= -gamma \n",
    "#     K -= K.max()\n",
    "#     np.exp(K, K)    # exponentiate K in-place \n",
    "#     return K \n",
    "  \n",
    "lp = LabelPropagation(kernel='rbf', gamma=10**-7, tol=10**-6, max_iter=10**6)\n",
    "lp.fit(x, y_lp)\n",
    "labels = lp.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels[len_train:] == y_num[len_train:]) / len(labels[len_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((x[0]-x[200]) ** 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
